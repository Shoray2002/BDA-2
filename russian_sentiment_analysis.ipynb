{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "\n",
    "<h1 style=\"background-color:#3c78aa;font-family:newtimeroman;font-size:250%;text-align:center;border-radius: 15px 50px;\">Libraires And Utilities</h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-ticks')\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import plotly.express as ex\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as pyo\n",
    "from plotly.subplots import make_subplots\n",
    "pyo.init_notebook_mode()\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from sklearn.decomposition import TruncatedSVD,PCA\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_data=pd.read_csv('russia_data.csv')\n",
    "russian_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_data = russian_data[['Title','Date_utc']].copy()\n",
    "title_data = title_data.dropna()\n",
    "\n",
    "# Renaming title column to 'title'\n",
    "title_data.rename(columns={'Title':'title','Date_utc':'timestamp'}, inplace=True)\n",
    "\n",
    "\n",
    "title_data.title =title_data.title.str.lower()\n",
    "\n",
    "#Remove handlers\n",
    "title_data.title = title_data.title.apply(lambda x:re.sub('@[^\\s]+','',x))\n",
    "\n",
    "# Remove URLS\n",
    "title_data.title = title_data.title.apply(lambda x:re.sub(r\"http\\S+\", \"\", x))\n",
    "\n",
    "# Remove all the special characters\n",
    "title_data.title = title_data.title.apply(lambda x:' '.join(re.findall(r'\\w+', x)))\n",
    "\n",
    "#remove all single characters\n",
    "title_data.title = title_data.title.apply(lambda x:re.sub(r'\\s+[a-zA-Z]\\s+', '', x))\n",
    "\n",
    "# Substituting multiple spaces with single space\n",
    "title_data.title = title_data.title.apply(lambda x:re.sub(r'\\s+', ' ', x, flags=re.I))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.1\"></a>\n",
    "\n",
    "<h1 style=\"background-color:orange;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 15px 50px;\">Sentiment Feature Creation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SIA()\n",
    "\n",
    "title_data['sentiments']           = title_data['title'].apply(lambda x: sid.polarity_scores(' '.join(re.findall(r'\\w+',x.lower()))))\n",
    "title_data['Positive Sentiment']   = title_data['sentiments'].apply(lambda x: x['pos']+1*(10**-6)) \n",
    "title_data['Neutral Sentiment']    = title_data['sentiments'].apply(lambda x: x['neu']+1*(10**-6))\n",
    "title_data['Negative Sentiment']   = title_data['sentiments'].apply(lambda x: x['neg']+1*(10**-6))\n",
    "\n",
    "title_data.drop(columns=['sentiments'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.2\"></a>\n",
    "\n",
    "<h1 style=\"background-color:orange;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 15px 50px;\">Naive Feature Extraction</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_data['# Of Words']          = title_data['title'].apply(lambda x: len(x.split(' ')))\n",
    "title_data['# Of StopWords']      = title_data['title'].apply(lambda x: len([word for word in x.split(' ') if word in list(STOPWORDS)]))\n",
    "title_data['Average Word Length'] = title_data['title'].apply(lambda x: np.mean(np.array([len(va) for va in x.split(' ') if va not in list(STOPWORDS)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.2\"></a>\n",
    "\n",
    "<h1 style=\"background-color:#3c78aa;font-family:newtimeroman;font-size:250%;text-align:center;border-radius: 15px 50px;\">Title Text Sentiment Analysis</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title('Distriubtion Of Title Sentiments Across Posts',fontsize=19,fontweight='bold')\n",
    "plt.xlabel('Sentiment Score',fontsize=15)\n",
    "# change size of tick labels\n",
    "plt.tick_params(labelsize=15)\n",
    "plt.ylabel('Frequency',fontsize=15)\n",
    "plt.hist(title_data['Positive Sentiment'],bins=25,alpha=0.5,label='Positive Sentiment',color='blue')\n",
    "plt.hist(title_data['Neutral Sentiment'],bins=25,alpha=0.5,label='Neutral Sentiment',color='orange')\n",
    "plt.hist(title_data['Negative Sentiment'],bins=25,alpha=0.5,label='Negative Sentiment',color='red')\n",
    "plt.legend()\n",
    "plt.rcParams.update({'legend.fontsize': '20'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.title('Distriubtion Of Sentiments Across Our Posts',fontsize=19,fontweight='bold')\n",
    "sns.kdeplot(title_data['Negative Sentiment'],bw_method=0.1)\n",
    "sns.kdeplot(title_data['Positive Sentiment'],bw_method=0.1)\n",
    "sns.kdeplot(title_data['Neutral Sentiment'],bw_method=0.1)\n",
    "plt.legend(['Negative Sentiment','Positive Sentiment','Neutral Sentiment'])\n",
    "plt.rcParams.update({'legend.fontsize': '15'})\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title('CDF Of Sentiments Across Our Posts',fontsize=19,fontweight='bold')\n",
    "sns.kdeplot(title_data['Negative Sentiment'],bw_method=0.1,cumulative=True)\n",
    "sns.kdeplot(title_data['Positive Sentiment'],bw_method=0.1,cumulative=True)\n",
    "sns.kdeplot(title_data['Neutral Sentiment'],bw_method=0.1,cumulative=True)\n",
    "plt.xlabel('Sentiment Value',fontsize=19)\n",
    "plt.legend(['Negative Sentiment','Positive Sentiment','Neutral Sentiment'])\n",
    "plt.rcParams.update({'legend.fontsize': '15'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: Apparently, The dominant sentiment among the Reddit post titles is by far neutral. Even more, there is a probability of 60% that a post title is classified to be completely neutral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.19378,
     "end_time": "2021-06-23T06:24:54.935137",
     "exception": false,
     "start_time": "2021-06-23T06:24:54.741357",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"4.2\"></a>\n",
    "\n",
    "<h1 style=\"background-color:orange;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 15px 50px;\">Title Text Decomposition Analysis</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Most_Positive = title_data[title_data['Positive Sentiment'].between(0.4,1)]['title']\n",
    "Most_Negative = title_data[title_data['Negative Sentiment'].between(0.25,1)]['title']\n",
    "\n",
    "Most_Positive_text = ' '.join(Most_Positive)\n",
    "Most_Negative_text = ' '.join(Most_Negative)\n",
    "\n",
    "\n",
    "pwc = WordCloud(width=600,height=400,collocations = False,background_color='white').generate(Most_Positive_text)\n",
    "\n",
    "plt.subplot(1,1,1)\n",
    "plt.title('Common Words Among Most Positive Post Titles',fontsize=16,fontweight='bold')\n",
    "plt.imshow(pwc)\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwc = WordCloud(width=600,height=400,collocations = False,background_color='white').generate(Most_Negative_text)\n",
    "\n",
    "plt.subplot(1,1,1)\n",
    "plt.title('Common Words Among Most Negative Post Titles',fontsize=16,fontweight='bold')\n",
    "plt.imshow(nwc)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_COMPONENTS = 450\n",
    "\n",
    "CVZ = CountVectorizer()\n",
    "SVD = TruncatedSVD(NUMBER_OF_COMPONENTS)\n",
    "\n",
    "text_data = title_data.title.copy()\n",
    "text_data = text_data.apply(lambda x: ' '.join([word for word in x.split() if word not in STOPWORDS and len(word) > 1]).strip())\n",
    "\n",
    "stemmer= PorterStemmer()\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "text_data = text_data.apply(lambda x: ' '.join([stemmer.stem(word) for word in word_tokenize(x)]))\n",
    "text_data = text_data.apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in word_tokenize(x)]))\n",
    "\n",
    "C_vector = CVZ.fit_transform(text_data)\n",
    "\n",
    "\n",
    "pc_matrix = SVD.fit_transform(C_vector)\n",
    "\n",
    "evr = SVD.explained_variance_ratio_\n",
    "total_var = evr.sum() * 100\n",
    "cumsum_evr = np.cumsum(evr)\n",
    "\n",
    "trace1 = {\n",
    "    \"name\": \"individual explained variance\", \n",
    "    \"type\": \"bar\", \n",
    "    'y':evr}\n",
    "trace2 = {\n",
    "    \"name\": \"cumulative explained variance\", \n",
    "    \"type\": \"scatter\", \n",
    "     'y':cumsum_evr}\n",
    "data = [trace1, trace2]\n",
    "layout = {\n",
    "    \"xaxis\": {\"title\": \"Principal components\"}, \n",
    "    \"yaxis\": {\"title\": \"Explained variance ratio\"},\n",
    "  }\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "fig.update_layout(     title='{:.2f}% of the Post Text Variance Can Be Explained Using {} Words'.format(np.sum(evr)*100,NUMBER_OF_COMPONENTS))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4e1d9a8909477db77738c33245c29c7265277ef753467dede8cf3f814cde494e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
